{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de información tipo 15, al que se añade informanción relevante de tipos 11, y 14\n",
    "\n",
    "tipo11: parcelas catastrales, coordenadas xy\n",
    "\n",
    "tipo14: construcciones dentro de las unidades constructivas: año antiguedad, año reforma si hay, superficie, garage\n",
    "\n",
    "tipo15: registro inmuebles. Tabla principal en la que poblar los datos relevantes de las otras tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### imports y definición de directorios\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "input_dir = '../../../data/clean/CAT/'\n",
    "out_dir = '../../../data/clean/ficheros_preparados/'\n",
    "processed_dir = '../../../data/clean/CAT/procesados/'\n",
    "\n",
    "pending_files = [f for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f))]\n",
    "\n",
    "pending_files = [f for f in pending_files if f[0:3] == 'T15']\n",
    "\n",
    "for f in pending_files:\n",
    "    \n",
    "    f15 = os.path.join(input_dir, f)    \n",
    "    \n",
    "    ## cargamos fichero tipo 15 (fincas)\n",
    "\n",
    "    indata15 = pd.read_csv(f15, low_memory=False, dtype='str')\n",
    "    cols_eliminar = indata15.columns[indata15.columns.str.contains('blanc')]\n",
    "    cols_eliminar = cols_eliminar.union(['tipo_reg', 'ctrl1', 'ctrl2', 'cmun_origen', 'cod_zona_concent', 'cod_poligono', 'cod_parcela', 'cod_paraje', 'nombre_paraje', 'num_orden_escrit_hori'])\n",
    "    indata15 = indata15.drop(cols_eliminar, axis = 1)\n",
    "\n",
    "    ## cargamos fichero tipo 14, para obtener m2 y años de construcción y reforma\n",
    "    ## t15 y t14 se cruzan por (parcela, num_cargo) en t15 y (parcela, num_orden_BI) en t14. PUeden existir\n",
    "    ## varios registros en t14 asociados a uno de 15. P. ej. viviendas con garajes. De aquí se puede marcar\n",
    "    ## que viviendas tienen garaje incluido para luego estimar el coste\n",
    "\n",
    "    f14 = f15.replace('T15', 'T14')\n",
    "    indata14 = pd.read_csv(f14, low_memory=False, dtype='str')\n",
    "    ## reducimos a sólo columnas de cruce y datos de interes\n",
    "    cols_interes = ['parcela_cat', 'num_orden_BI', 'tipo_reforma', 'anio_ref', 'anio_antiguedad', 'local_interior', 'm2_total', 'm2_porches_terr', 'm2_imputables_loc', 'tipologia_constr', 'planta']\n",
    "    indata14 = indata14.reindex(columns=cols_interes)\n",
    "\n",
    "    ## muestra para acelerar desarrollo, comentar en producción\n",
    "    #indata15 = indata15[0:200000]\n",
    "    #indata14 = indata14[0:200000]\n",
    "\n",
    "    ## dejamos en t14 sólo registros relacionados con t15 que sean viviendas, el resto no es de interés. Mejora\n",
    "    ## rendimiento de groupby/transform posteriores\n",
    "    indata15['parcela_cat'].fillna('No info', inplace = True)\n",
    "    indata15['num_cargo'].fillna('No info', inplace = True)\n",
    "    duplas_viv = indata15[indata15['clave_grupo_BI'] == 'V'].groupby(['parcela_cat', 'num_cargo'])\n",
    "    duplas_viv = duplas_viv.size().reset_index()\n",
    "    duplas_viv = duplas_viv.drop(0, axis = 1)\n",
    "    indata14 = pd.merge(indata14, duplas_viv, left_on=['parcela_cat','num_orden_BI'], right_on=['parcela_cat', 'num_cargo'])\n",
    "\n",
    "\n",
    "    ## seleccionamos las duplas de t14 con más de un registro y alguno en plantas negativas -> viviendas con garages\n",
    "    indata14['parcela_cat'].fillna('No info', inplace = True)\n",
    "    indata14['num_orden_BI'].fillna('No info', inplace = True)\n",
    "    ## la línea de abajo es extremadamente lenta, preguntar pq. Sustituyo por group y merge\n",
    "    #indata14['registros'] = indata14.groupby(['parcela_cat', 'num_orden_BI'])[['parcela_cat']].transform(lambda x: len(x))\n",
    "    grupo_comp = indata14.groupby(['parcela_cat', 'num_orden_BI'])[['parcela_cat']].size().reset_index()\n",
    "    indata14 = pd.merge(indata14, grupo_comp, how='left', left_on=['parcela_cat', 'num_orden_BI'], right_on=['parcela_cat', 'num_orden_BI'])\n",
    "    indata14.rename(columns={0:'registros'}, inplace=True)\n",
    "    indata14['planta'].fillna('No info', inplace = True)\n",
    "    indata14['posible_garage'] = indata14.apply(lambda x: 1 if ((x['registros'] > 1) & (x['planta'][0] == '-')) else 0, axis=1)\n",
    "    duplas14_garage = indata14[indata14['posible_garage'] == 1].groupby(['parcela_cat', 'num_orden_BI']).size().reset_index()\n",
    "    duplas14_garage.drop(0, axis = 1, inplace=True)\n",
    "    duplas14_garage['garage']=1\n",
    "\n",
    "    ## marcamos en t15 las viviendas con garage\n",
    "    indata15 = pd.merge(indata15, duplas14_garage, how='left', left_on=['parcela_cat', 'num_cargo'], right_on=['parcela_cat','num_orden_BI'])\n",
    "    indata15['garage'].fillna(0, inplace = True)\n",
    "    indata15.drop('num_orden_BI', axis = 1, inplace = True)\n",
    "    indata15['garage'] = indata15['garage'].map(int)\n",
    "\n",
    "    ## dejamos un unico valor de año, el maximo de la reforma y de antiguedad\n",
    "\n",
    "    years = ['anio_ref', 'anio_antiguedad']\n",
    "    indata14[years] = indata14[years].apply(lambda x: x.fillna(0))\n",
    "    indata14[years] = indata14[years].applymap(int)\n",
    "    indata14['aniot14'] = np.maximum(indata14['anio_ref'], indata14['anio_antiguedad'])\n",
    "    duplas14_maxyear = indata14.groupby(['parcela_cat', 'num_orden_BI'])['aniot14'].max().reset_index()\n",
    "    indata15 = pd.merge(indata15, duplas14_maxyear, how='left', left_on=['parcela_cat', 'num_cargo'], right_on=['parcela_cat','num_orden_BI'])\n",
    "    years = ['antiguedad_BI', 'aniot14']\n",
    "    indata15[years] = indata15[years].apply(lambda x: x.fillna(0))\n",
    "    indata15[years] = indata15[years].applymap(int)\n",
    "    indata15['anio_mejor'] = np.maximum(indata15['antiguedad_BI'], indata15['aniot14'])\n",
    "\n",
    "    ## poblar con las coordenadas xy desde tipo 11 parcelas\n",
    "\n",
    "    f11 = f15.replace('T15', 'T11')\n",
    "    indata11 = pd.read_csv(f11, low_memory=False, dtype='str')\n",
    "    ## Solo necesitamos las coordenadas y la proyección de esta tabla\n",
    "    ## convertimos las coordenadas a float, los 2 ultimos digitos son el decimal\n",
    "    cols_coor = indata11.columns[indata11.columns.str.contains('coor')]\n",
    "    indata11[cols_coor] = indata11[cols_coor].apply(lambda x: x.fillna(0))\n",
    "    indata11[cols_coor] = indata11[cols_coor].applymap(lambda x: int(x)/100.0)\n",
    "    ## quitar 'EPSG:' de huso_geo\n",
    "    indata11['huso_geo'].fillna('', inplace = True)\n",
    "    indata11['huso_geo'] = indata11['huso_geo'].apply(lambda x: x[5:])\n",
    "\n",
    "    indata15 = pd.merge(indata15, indata11[['parcela_cat', 'x_coor', 'y_coor', 'huso_geo']], how='left', left_on='parcela_cat', right_on='parcela_cat')\n",
    "\n",
    "    ## grabamos el fichero de resultado \n",
    "    fbienesinmuebles = f.replace('T15', 'BI')\n",
    "    fbienesinmuebles = fbienesinmuebles.replace('.gz', '')\n",
    "    fbienesinmuebles = os.path.join(out_dir, fbienesinmuebles)\n",
    "\n",
    "    indata15.to_csv(fbienesinmuebles, index=False, sep='^', quoting= csv.QUOTE_NONNUMERIC, encoding='utf-8')\n",
    "    !gzip -f $fbienesinmuebles\n",
    "\n",
    "    ## movemos los ficheros originales al directorio de procesados\n",
    "    !mv $f11 $processed_dir\n",
    "    !mv $f14 $processed_dir\n",
    "    !mv $f15 $processed_dir\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
